# AI-Honor-Conference-CS231n
SungKongHoe Univ.  AI Honor Conference 1st CS231n study

<br>
2023ë…„ë„ ì„±ê³µíšŒëŒ€í•™êµ ì¸ê³µì§€ëŠ¥ ëª…ì˜ˆí•™íšŒ 1ê¸° ì‹¬í™”í•™ìˆ  ìŠ¤í„°ë””ì…ë‹ˆë‹¤.
<br>
<br>
<h2> Member </h2>
- ğŸ§‘ ë¥˜ì°½í›ˆ
<br> - ğŸ§‘ ë°•ë¬´ì¬
<br> - ğŸ§‘ ìµœë¯¼ìš°

<br>
<br>

<h2> ì§„í–‰ë°©ì‹ </h2>
- CS231n ê°•ì˜ ë“£ê¸°
<br> - ê°œë³„ì  ê°•ì˜ ì •ë¦¬
<br> - ê³µë¶€ ë¦¬ë·°  
<br> - OpenCVí™œìš© ì–¼êµ´íƒì§€ ì‹¤ìŠµ
<br>
<br>

<h2> ìŠ¤í„°ë”” ì¼ì • </h5>


|ìˆœë²ˆ|ë‚ ì§œ|ì§„í–‰|
|:---:|:---:|:---:|
|1|*3/6*|**Lecture 1**|
|2|*3/13*|**Lecture 2, Lecture 3**|
|3|*3/20*|**Lecture 4, Lecture 5**|
|4|*3/29*|**Lecture 6, Lecture 7**|
|5|*4/3*|**Lecture 8, Lecture 9**|
|6|*5/1*|**Lecture 10, Lecture 11**|
|7|*5/8*|**Lecture 12, Lecture 13**|
|8|*5/15*|**Lecture 14, Lecture 15**|
|9|*5/22*|**Lecture 16 & ë°œí‘œ**|
|10|*5/29*|**ì–¼êµ´ íƒì§€ ì‹¤ìŠµ ë§ˆë¬´ë¦¬**|

<br>
<br>
<h2> ìŠ¤í„°ë”” ì§„í–‰ </h2>
<br>
-3/6: ìŠ¤í„°ë”” ì§„í–‰ ê³„íš ì„¤ëª…, Lecture 1 ë¦¬ë·° ì§„í–‰, í”„ë¡œì íŠ¸ ì§„í–‰ ë…¼ì˜
<br>
<br> -3/13: Nearest Neighbor(ìµœê·¼ì ‘ ì´ì›ƒ), KNN(k-ìµœê·¼ì ‘ ì´ì›ƒ), í•˜ì´í¼íŒŒë¼ë¯¸í„°, ì„ í˜•ë¶„ë¥˜, ì†ì‹¤í•¨ìˆ˜(SVM, SoftMax), Optimization, Image Features ì´ë¡  í•™ìŠµ.
<br>
<br> -3/20: Back propagation(ì—­ì „íŒŒ), Neural Network(ì‹ ê²½ë§), ì‹ ê²½ë§ ì—­ì‚¬, ConvNet êµ¬ì¡°, spartial dimension(ê³µê°„ ì°¨ì›)
<br>
<br> -3/29: í™œì„±í™” í•¨ìˆ˜(Sigmoid, ReLU, Leaky ReLU, PReLU, ELU, Maxout), ë°ì´í„° ì „ì²˜ë¦¬(AlexNet, VGGNet), ê°€ì¤‘ì¹˜, í•™ìŠµë¥  ì¡°ì •, BabySitting the Learning Process, ìµœì í™”(SGD, SGD Momentum, Nesterov, AdaGrad, Adam, ë‰´ëŸ°ìŠ¤í…, ëª¨ë¸ ì•™ìƒë¸”), ì •ê·œí™”(ë“œë¡­ì•„ì›ƒ, ì—­ ë“œë¡­ì•„ì›ƒ, ë°°ì¹˜ ì •ê·œí™”), Transfor Learning ì´ë¡  í•™ìŠµ ë° OpenCV í™œìš© ì„±ë³„, ë‚˜ì´ ì¸ì‹ ì½”ë“œ ì‹¤ìŠµ.
<br>
<br> -4/3: ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ ì—­ì‚¬(Caffe/ Caffe2, Theano/ TensorFlow, Torch/ Pytorch)ì™€ ê°ê°ì˜ í˜•íƒœ, ì¥ë‹¨ì , CNNì—°êµ¬(LeNet-5, ZFNet, VGGNet, GoogLeNet, ResNet, NiN, DenseNet, SqueezeNet)ì˜ ë°©ì‹.
