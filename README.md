# AI-Honor-Conference-CS231n
SungKongHoe Univ.  AI Honor Conference 1st CS231n study

<br>
2023년도 성공회대학교 인공지능 명예학회 1기 심화학술 스터디입니다
<br>
<br>
<h2> Member </h2>
- 🧑 류창훈
<br> - 🧑 박무재
<br> - 🧑 최민우

<br>
<br>

<h2> 진행방식 </h2>
- CS231n 강의 듣기
<br> - 개별적 강의 정리
<br> - 공부 리뷰  
<br> - OpenCV활용 얼굴탐지 실습
<br> - CNN논문 리딩
<br> - Kaggle 독버섯 분류 코드 분석
<br>
<br>

<h2> 스터디 일정 </h5>


|순번|날짜|진행|
|:---:|:---:|:---:|
|1|*3/6*|**Lecture 1**|
|2|*3/13*|**Lecture 2, Lecture 3**|
|3|*3/20*|**Lecture 4, Lecture 5**|
|4|*3/29*|**Lecture 6, Lecture 7**|
|5|*4/3*|**Lecture 8, Lecture 9**|
|6|*5/1*|**Lecture 10, Lecture 11**|
|7|*5/8*|**Lecture 12, Lecture 13**|
|8|*5/10*|**Lecture 14**|
|9|*5/15 ~ 끝날 때 까지<br>(최대한 빠르게)*|**Kaggle 독버섯 분류 코드 분석**|
|10|*~6/14*|**CNN관련 논문 리딩<br>CS231n 개인 블로그 업로드 마무리**|

<br>
<br>
<h2> 스터디 진행 </h2>
<br>
-3/6: 스터디 진행 계획 설명, Lecture 1 리뷰 진행, 프로젝트 진행 논의
<br>
<br> -3/13: Nearest Neighbor(최근접 이웃), KNN(k-최근접 이웃), 하이퍼파라미터, 선형분류, 손실함수(SVM, SoftMax), Optimization, Image Features 이론 학습.
<br>
<br> -3/20: Back propagation(역전파), Neural Network(신경망), 신경망 역사, ConvNet 구조, spartial dimension(공간 차원)
<br>
<br> -3/29: 활성화 함수(Sigmoid, ReLU, Leaky ReLU, PReLU, ELU, Maxout), 데이터 전처리(AlexNet, VGGNet), 가중치, 학습률 조정, BabySitting the Learning Process, 최적화(SGD, SGD Momentum, Nesterov, AdaGrad, Adam, 뉴런스텝, 모델 앙상블), 정규화(드롭아웃, 역 드롭아웃, 배치 정규화), Transfor Learning 이론 학습 및 OpenCV 활용 성별, 나이 인식 코드 실습.
<br>
<br> -4/3: 딥러닝 프레임워크 역사(Caffe/ Caffe2, Theano/ TensorFlow, Torch/ Pytorch)와 각각의 형태, 장단점, CNN연구(LeNet-5, ZFNet, VGGNet, GoogLeNet, ResNet, NiN, DenseNet, SqueezeNet)의 방식.
<br>
<br> - 5/1: 계산 그래프 활용한 RNN이론 실습. CNN과 RNN의 연관성. Vanilla RNN, LSTM, GRU 각각의 구성. 이미지 분리(Segmentation), 위치찾기(Localization), 탐지(Detection) 방식 학습.
<br>
<br> -5/8: CNN계층 내부에서 어떤 계산이 일어나는지에 대한 학습, 그간의 연구 방식. Unsupervised Learning(비지도 학습)의 형태, 연구 살펴보기.
<br>
<br> -5/10: 강화학습(Reinforcement Learning)의 개념, MDP(Markov Decision Process) 수식, 기댓값 수식화(Value function, Q-Value function), Q-learning, Policy Gradients(Q-learning보다 진보된 방식, 기울기를 구한 최적의 정책 찾기 가능), 분산값 줄이는 방식, Actor-Critic 알고리즘 구조.
<br>
<br> -5/15: 캐글 독버섯 데이터 DecisionTreeClassifier, RandomForestClassifier, XGBClassifier, ExtraTreeClassifier, VotingClassifier로 정확도 비교. 
<br>
<br> -5/17: 캐글 독버섯 데이터 전처리, 분류 후 여러 시각화 적용.
<br>
<br> -5/22: DenseNet논문 리딩 후 요약, 토론.
<br>
<br> -5/24: DenseNet 구현.
